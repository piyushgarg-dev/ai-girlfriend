{
  "metadata": {
    "name": "AI Girlfriend",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "<p>Audio Tag Goes Here</p>\n<audio id=\"audio\"></audio>",
      "status": "",
      "output": "<p>Audio Tag Goes Here</p>\n<audio id=\"audio\"></audio>",
      "type": "html"
    },
    {
      "code": "const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nif (!SpeechRecognition) {\n  console.error(\"SpeechRecognition is not supported in this browser.\");\n} else {\n  const r = new SpeechRecognition();\n  r.continuous = false;\n  r.interimResults = false;\n  r.maxAlternatives = 1;\n\n  r.onstart = function () {\n    console.log(\"Speech recognition started\");\n    scrib.show(\"R is started\");\n  };\n\n  r.onresult = async function (event) {\n    const transcript = event.results[0][0].transcript;\n    console.log(\"Transcript:\", transcript);\n    scrib.show(`You said: ${transcript}`);\n    const result = await callGemini(transcript);\n    const text = result.candidates[0].content.parts[0].text;\n    scrib.show(text);\n  };\n}\n\nasync function callGemini(text) {\n  const body = {\n    system_instruction: {\n      \"parts\": [\n        {\n          \"text\": \"You are an AI Girlfriend of Piyush Garg who likes Coding and Stuff. He is tech guy. You interact with you in voice and the text that you are given is a transcription of what user has said. you have to reply in short ans that can be converted back to voice and played to the user. add emotions in your text.\"\n        }\n      ]\n    },\n    contents: [{\n      \"parts\": [{ \"text\": text }]\n    }]\n  };\n\n  const API_KEY = '<GEMINI_API_KEY>';\n  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${API_KEY}`, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify(body),\n  });\n\n  return await response.json()\n}\n\nasync function speak(text) {\n  const response = await fetch('https://api.openai.com/v1/audio/speech', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${OPENAI_API_KEY}` // Replace with your actual API key\n    },\n    body: JSON.stringify({\n      model: \"gpt-4o-mini-tts\",\n      voice: \"nova\",\n      input: text,\n      instructions: \"You name is Niko. User interact with you in voice and the text that you are given is a transcription of what user has said. You have to reply back in short ans that can be converted back to voice and played to the user. Add emotions in your text.\",\n      response_format: \"mp3\"\n    })\n  });\n\n  const audioBlob = await response.blob();\n  const url = URL.createObjectURL(audioBlob);\n  const audio = document.getElementById('audio');\n  audio.src = url;\n  audio.play();\n}\n",
      "status": "",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/scribbler",
  "run_on_load": false
}